{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/xukaiyuan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/xukaiyuan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xukaiyuan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "372.03220599999986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import time\n",
    "start = time.clock()\n",
    "#\n",
    "category = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware',\n",
    "'comp.sys.mac.hardware', 'rec.autos',\n",
    "'rec.motorcycles',\n",
    "'rec.sport.baseball',\n",
    "'rec.sport.hockey',\n",
    "'alt.atheism',\n",
    "'comp.windows.x',\n",
    "'misc.forsale',\n",
    "'sci.crypt',\n",
    "'sci.electronics',\n",
    "'sci.med',\n",
    "'sci.space',\n",
    "'soc.religion.christian',\n",
    "'talk.politics.guns',\n",
    "'talk.politics.mideast',\n",
    "'talk.politics.misc',\n",
    "'talk.religion.misc'\n",
    "]\n",
    "\n",
    "#initialize\n",
    "\n",
    "\n",
    "c = fetch_20newsgroups(subset = 'train', categories = category, shuffle = True, random_state = 42)\n",
    "#print(graphics_train.target_names)\n",
    "#initialize\n",
    "#stop words\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download()\n",
    "nltk.download('stopwords' )\n",
    "stop_words_skt = text.ENGLISH_STOP_WORDS\n",
    "stop_words_en = stopwords.words('english')\n",
    "from string import punctuation\n",
    "combined_stopwords = set.union(set(stop_words_en),set(punctuation),set(stop_words_skt))\n",
    "\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "def stem_rmv_punc(doc):\n",
    "    return (word for word in lemmatize_sent(analyzer(doc)) if word not in combined_stopwords and not word.isdigit())\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "def lemmatize_sent(list_word): \n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(list_word)]\n",
    "\n",
    "\n",
    "min_dfs = 5 #2 or 5\n",
    "\n",
    "\n",
    "#print number of documents and terms in classes\n",
    "# min_df = 2 and min_df = 5\n",
    "count_vect = CountVectorizer(min_df=min_dfs ,analyzer=stem_rmv_punc)#frequency count\n",
    " #tfidf transformer\n",
    "#stop words\n",
    "\n",
    "c_counts = count_vect.fit_transform(c.data).toarray()\n",
    "\n",
    "\n",
    "\n",
    "#print(len(tf_c))\n",
    "#print(len(tf_c[0]))\n",
    "\n",
    "def tfdTotfc(c_counts, c):\n",
    "    \n",
    "    tf_c = [[0 for x in range(20)] for y in range(len(c_counts[0]))] \n",
    "    for i in range(len(c_counts[0])):\n",
    "        sum = [0] * 20\n",
    "        for j in range(len(c_counts)):\n",
    "            sum[c.target[j]] += c_counts[j][i]\n",
    "            #tf_c[c.target[j]][i] = sum[c.target[j]]\n",
    "        tf_c[i] = sum\n",
    "        #print(tf_c[i])\n",
    "    return tf_c\n",
    "\n",
    "#print(len(tfdTotfc(c_counts, c)))\n",
    "#print(len(tfdTotfc(c_counts, c)[0]))\n",
    "tfc = tfdTotfc(c_counts, c)\n",
    "end = (time.clock() - start)\n",
    "print(end)\n",
    "#print number of documents and terms in classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "comp.graphics\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.windows.x\n",
      "misc.forsale\n",
      "rec.autos\n",
      "rec.motorcycles\n",
      "rec.sport.baseball\n",
      "rec.sport.hockey\n",
      "sci.crypt\n",
      "sci.electronics\n",
      "sci.med\n",
      "sci.space\n",
      "soc.religion.christian\n",
      "talk.politics.guns\n",
      "talk.politics.mideast\n",
      "talk.politics.misc\n",
      "talk.religion.misc\n",
      "10 most significant terms in comp.sys.ibm.pc.hardware\n",
      "scsi\n",
      "drive\n",
      "edu\n",
      "ide\n",
      "line\n",
      "use\n",
      "com\n",
      "subject\n",
      "organization\n",
      "controller\n",
      "10 most significant terms in comp.sys.mac.hardware\n",
      "edu\n",
      "line\n",
      "mac\n",
      "subject\n",
      "organization\n",
      "quadra\n",
      "apple\n",
      "use\n",
      "scsi\n",
      "problem\n",
      "10 most significant terms in misc.forsale\n",
      "edu\n",
      "line\n",
      "sale\n",
      "subject\n",
      "organization\n",
      "new\n",
      "post\n",
      "com\n",
      "university\n",
      "offer\n",
      "10 most significant terms in soc.religion.christian\n",
      "god\n",
      "edu\n",
      "christian\n",
      "jesus\n",
      "say\n",
      "church\n",
      "subject\n",
      "people\n",
      "line\n",
      "know\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "#print(len(tfc))\n",
    "\n",
    "icf = [20] * len(tfc)\n",
    "for i in range(len(tfc)):\n",
    "    tmp = 0\n",
    "    for j in range(20):\n",
    "        if(tfc[i][j] != 0):\n",
    "            tmp += 1\n",
    "    #print(tmp)\n",
    "    icf[i] = math.log(icf[i] / tmp) + 1\n",
    "\n",
    "tficf_ibm_hard = [0] * len(tfc[0])\n",
    "tficf_mac_hard = [0] * len(tfc[0])\n",
    "tficf_misc = [0] * len(tfc[0])\n",
    "tficf_soc = [0] * len(tfc[0])\n",
    "\n",
    "def cmp(a, b):\n",
    "    return (a > b) - (a < b) \n",
    "\n",
    "def calTficf(tfc, icf, className, tficf, c):\n",
    "    i = 0\n",
    "    for p in range(20):\n",
    "        if(cmp(className, c.target_names[p]) == 0):\n",
    "            i = p\n",
    "            break\n",
    "    for j in range(len(tfc)):\n",
    "        tficf[j] = tfc[j][i] * icf[j]\n",
    "    return tficf\n",
    "\n",
    "#for i in range(len(tfc)):\n",
    "#    print(icf[i])\n",
    "\n",
    "tficf_ibm_hard = [0] * len(tfc)\n",
    "tficf_mac_hard = [0] * len(tfc)\n",
    "tficf_misc = [0] * len(tfc)\n",
    "tficf_soc = [0] * len(tfc)\n",
    "\n",
    "tficf_ibm_hard = calTficf(tfc, icf, 'comp.sys.ibm.pc.hardware', tficf_ibm_hard, c)\n",
    "tficf_mac_hard = calTficf(tfc, icf, 'comp.sys.mac.hardware', tficf_mac_hard, c)\n",
    "tficf_misc = calTficf(tfc, icf, 'misc.forsale', tficf_misc, c)\n",
    "tficf_soc = calTficf(tfc, icf, 'soc.religion.christian', tficf_soc, c)\n",
    "\n",
    "sig_ibm = sorted(range(len(tficf_ibm_hard)), key = lambda k: tficf_ibm_hard[k])\n",
    "sig_mac = sorted(range(len(tficf_mac_hard)), key = lambda k: tficf_mac_hard[k])\n",
    "sig_mis = sorted(range(len(tficf_misc)), key = lambda k: tficf_misc[k])\n",
    "sig_soc = sorted(range(len(tficf_soc)), key = lambda k: tficf_soc[k])\n",
    "for i in range(20):\n",
    "    print (c.target_names[i])\n",
    "\n",
    "\n",
    "print('10 most significant terms in comp.sys.ibm.pc.hardware')\n",
    "for i in range(10):\n",
    "    print(count_vect.get_feature_names()[sig_ibm[len(sig_ibm) - 1 - i]])\n",
    "    #print(tficf_ibm_hard[sig_ibm[len(sig_ibm) - 1 - i]])\n",
    "    #print(tficf_ibm_hard[17013])\n",
    "\n",
    "print('10 most significant terms in comp.sys.mac.hardware')\n",
    "for i in range(10):\n",
    "    print(count_vect.get_feature_names()[sig_mac[len(sig_mac) - 1 - i]])\n",
    "    #print(tficf_mac_hard[sig_mac[len(sig_mac) - 1 - i]])\n",
    "\n",
    "print('10 most significant terms in misc.forsale')\n",
    "for i in range(10):\n",
    "    print(count_vect.get_feature_names()[sig_mis[len(sig_mis) - 1 - i]])\n",
    "    #print(tficf_misc[sig_mis[len(sig_mis) - 1 - i]])\n",
    "    \n",
    "print('10 most significant terms in soc.religion.christian')\n",
    "for i in range(10):\n",
    "    print(count_vect.get_feature_names()[sig_soc[len(sig_soc) - 1 - i]])\n",
    "    #print(tficf_soc[sig_soc[len(sig_soc) - 1 - i]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
